{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import pickle\n",
    "import math\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from scipy import stats\n",
    "    \n",
    "\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def countDiffMasks(mask1,mask2):\n",
    "    total_diff=0\n",
    "    for i in range(len(mask1)):\n",
    "        m_1=mask1[i].flatten()\n",
    "        m_2=mask2[i].flatten()\n",
    "        count_same=(m_1 == m_2).sum()\n",
    "        count_different=m_1.flatten().shape[0]-count_same\n",
    "        total_diff+=count_different\n",
    "    return total_diff\n",
    "\n",
    "\n",
    "def get_mask_compression(mask_whole_model):\n",
    "    num_total=0\n",
    "    num_non_zeros=0\n",
    "    for mask_each_layer in mask_whole_model:\n",
    "        num_total+=torch.numel(mask_each_layer)\n",
    "        num_non_zeros+=torch.count_nonzero(mask_each_layer)\n",
    "        \n",
    "    return (num_total-num_non_zeros)/num_total\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def prune_model_get_mask(model,prune_rate):\n",
    "    '''\n",
    "    works purely on the model to get\n",
    "    mask\n",
    "    '''\n",
    "    mask_whole_model=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)\n",
    "#             print(nm,params.shape)\n",
    "            abs_var=torch.std(torch.abs(params.data))\n",
    "#             print(abs_var)\n",
    "#             print(params)\n",
    "            threshold=abs_var*prune_rate\n",
    "            num_components=params.shape[0]\n",
    "            for index_component in range(num_components):\n",
    "                values=params[index_component]            \n",
    "                re_shaped_values=values.flatten()                \n",
    "                mask_vals = (torch.abs(re_shaped_values)>threshold).float()\n",
    "                mask_vals=mask_vals.reshape(values.shape)\n",
    "#                 print(mask_vals.shape)\n",
    "                mask_layer[index_component]=mask_vals\n",
    "            mask_whole_model.append(mask_layer)\n",
    "    return mask_whole_model\n",
    " \n",
    "    \n",
    "def get_thresholds_each_layer(model,prune_rate):\n",
    "    thresholds_per_layer=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)\n",
    "            abs_std=torch.std(torch.abs(params.data))\n",
    "            threshold=abs_std*prune_rate\n",
    "            thresholds_per_layer.append(threshold)\n",
    "    return thresholds_per_layer\n",
    "    \n",
    "                \n",
    "def apply_mask_model(model,list_mask_whole_model):\n",
    "    mask_layer_count=0\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=list_mask_whole_model[mask_layer_count]\n",
    "            with torch.no_grad():\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#                 print(\"Devices are \",params.device,mask_layer.device)\n",
    "                mask_layer=mask_layer.to(device)\n",
    "    \n",
    "                params.data=params.data*mask_layer            \n",
    "            mask_layer_count+=1\n",
    "    \n",
    "\n",
    "def store_weights_in_dic(weight_description,model):\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            if nm not in weight_description:\n",
    "                weight_description[nm]={}\n",
    "            num_components=params.shape[0]\n",
    "            for index_component in range(num_components):\n",
    "                if index_component not in weight_description[nm]:\n",
    "                    weight_description[nm][index_component]={}\n",
    "                values=params[index_component]\n",
    "                flat_values=values.flatten()\n",
    "                for index_wt in range(flat_values.shape[0]):\n",
    "                    if index_wt not in weight_description[nm][index_component]:\n",
    "                        weight_description[nm][index_component][index_wt]=[]\n",
    "                    weight_description[nm][index_component][index_wt].append(flat_values[index_wt].detach().item())\n",
    "    return weight_description\n",
    "\n",
    "\n",
    "def get_boolean_dict_weight_dict(weight_description,prune_rate,thresholds_per_layer,last_few):\n",
    "    '''\n",
    "    works on the dictionary of weights\n",
    "    to create a dict of 1s and 0s to show\n",
    "    how many times weight is more than threshold\n",
    "    per layer\n",
    "    '''\n",
    "    boolean_weight_description={}\n",
    "    count=0\n",
    "    for layer in weight_description.keys():  \n",
    "#         print(\"Count = \",count)\n",
    "        threshold_this_layer=thresholds_per_layer[count]\n",
    "#         print(\"Threshold for layer \",count,layer,\"is \",threshold_this_layer)\n",
    "        if layer not in boolean_weight_description:\n",
    "            boolean_weight_description[layer]={}\n",
    "        for index_component in weight_description[layer].keys():\n",
    "            if index_component not in boolean_weight_description[layer]:\n",
    "                boolean_weight_description[layer][index_component]={}\n",
    "            for index_wt in weight_description[layer][index_component].keys():\n",
    "                if index_wt not in boolean_weight_description[layer][index_component]:\n",
    "                    boolean_weight_description[layer][index_component][index_wt]=[]\n",
    "                all_wts=weight_description[layer][index_component][index_wt][:-last_few]\n",
    "                all_wts_boolean=[]\n",
    "                for wt in all_wts:\n",
    "                    if abs(wt)>threshold_this_layer:\n",
    "                        all_wts_boolean.append(1)\n",
    "                    else:\n",
    "                        all_wts_boolean.append(0)\n",
    "                boolean_weight_description[layer][index_component][index_wt]=all_wts_boolean                    \n",
    "        count+=1\n",
    "        \n",
    "    return boolean_weight_description\n",
    "\n",
    "\n",
    "\n",
    "def get_mean_dict_weight_dict(weight_description,last_few):\n",
    "    '''\n",
    "    works on the dictionary of weights\n",
    "    to create a dict of mean of weights simply\n",
    "    for the last few epochs\n",
    "    '''\n",
    "    mean_weight_description={}\n",
    "\n",
    "    for layer in weight_description.keys():  \n",
    "        if layer not in mean_weight_description:\n",
    "            mean_weight_description[layer]={}\n",
    "        for index_component in weight_description[layer].keys():\n",
    "            if index_component not in mean_weight_description[layer]:\n",
    "                mean_weight_description[layer][index_component]={}\n",
    "            for index_wt in weight_description[layer][index_component].keys():\n",
    "                if index_wt not in mean_weight_description[layer][index_component]:\n",
    "                    mean_weight_description[layer][index_component][index_wt]=[]\n",
    "                all_wts=weight_description[layer][index_component][index_wt][-last_few:]                \n",
    "                all_wts_mean=np.mean(all_wts)                \n",
    "                mean_weight_description[layer][index_component][index_wt]=all_wts_mean                    \n",
    "        \n",
    "    return mean_weight_description\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# create mask from boolean weight dictionary\n",
    "def create_mask_from_boolean_wt(model,boolean_wt_dict):\n",
    "    mask_whole_model=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)\n",
    "#             print(nm,params.shape)\n",
    "            abs_var=torch.var(torch.abs(params.data))\n",
    "#             print(abs_var)\n",
    "#             print(params)\n",
    "#             threshold=abs_var*prune_rate\n",
    "            num_components=params.shape[0]\n",
    "            for index_component in range(num_components):\n",
    "                values=params[index_component]            \n",
    "                re_shaped_values=values.flatten() \n",
    "                mask_vals=[]\n",
    "                for val_index in range(re_shaped_values.shape[0]):\n",
    "                    boolean_vals=boolean_wt_dict[nm][index_component][val_index]\n",
    "                    m = stats.mode(boolean_vals)\n",
    "#                     print(\"Verdict for this weight is \",m[0][0])\n",
    "                    mask_vals.append(m[0][0])\n",
    "#                 mask_vals = (torch.abs(re_shaped_values)>threshold).float()                \n",
    "                mask_vals=np.asarray(mask_vals)\n",
    "                mask_vals=mask_vals.reshape(values.shape)\n",
    "#                 print(mask_vals.shape)\n",
    "                mask_layer[index_component]=torch.from_numpy(mask_vals)\n",
    "            mask_whole_model.append(mask_layer)\n",
    "    return mask_whole_model\n",
    "\n",
    "\n",
    "         \n",
    "def create_mask_from_mean_wt(model,mean_weight_description,prune_rate):\n",
    "    mask_whole_model=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)    \n",
    "            # get all mean weights for this layer\n",
    "            mean_wt_layer=mean_weight_description[nm]\n",
    "            wts_this_layer=[]\n",
    "            for neuron_index in list(mean_wt_layer.keys()):\n",
    "                all_wts_this_neu=mean_wt_layer[neuron_index]\n",
    "\n",
    "                for weight_index in list(mean_wt_layer[neuron_index].keys()):\n",
    "                    wts_this_layer.append(mean_wt_layer[neuron_index][weight_index])\n",
    "            # end of all neurons\n",
    "#             print(\"first 5 Mean weights this layer are \",wts_this_layer[:5])\n",
    "            abs_var=torch.std(torch.FloatTensor(wts_this_layer))\n",
    "#             print(\"standard dev is \",abs_var)\n",
    "            threshold=abs_var*prune_rate\n",
    "#             print(\"Threshold is \",threshold)\n",
    "            num_components=params.shape[0]            \n",
    "            for index_component in range(num_components):\n",
    "                values=params[index_component]            \n",
    "                re_shaped_values=values.flatten()                \n",
    "                mask_vals = (torch.abs(re_shaped_values)>threshold).float()\n",
    "                mask_vals=mask_vals.reshape(values.shape)\n",
    "#                 print(mask_vals.shape)\n",
    "                mask_layer[index_component]=mask_vals\n",
    "            mask_whole_model.append(mask_layer)\n",
    "    return mask_whole_model\n",
    "            \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "def get_weighted_mean_dict_weight_dict(weight_description,last_few):\n",
    "    '''\n",
    "    works on the dictionary of weights\n",
    "    to create a dict of mean of weights     \n",
    "    for the last few epochs\n",
    "    and gives a weightage to each weight value\n",
    "    depending on the epoch\n",
    "    last epoch highest weight\n",
    "    '''\n",
    "    weighted_mean_weight_description={}\n",
    "\n",
    "    for layer in weight_description.keys():  \n",
    "        if layer not in weighted_mean_weight_description:\n",
    "            weighted_mean_weight_description[layer]={}\n",
    "        for index_component in weight_description[layer].keys():\n",
    "            if index_component not in weighted_mean_weight_description[layer]:\n",
    "                weighted_mean_weight_description[layer][index_component]={}\n",
    "            for index_wt in weight_description[layer][index_component].keys():\n",
    "                if index_wt not in weighted_mean_weight_description[layer][index_component]:\n",
    "                    weighted_mean_weight_description[layer][index_component][index_wt]=[]\n",
    "                all_wts=weight_description[layer][index_component][index_wt][-last_few:]\n",
    "                i_weights=[math.sqrt(i) for i in range(1,last_few+1)]\n",
    "#                 print(all_wts,i_weights)\n",
    "                all_wts_mean=np.average(all_wts,weights=i_weights)                \n",
    "                weighted_mean_weight_description[layer][index_component][index_wt]=all_wts_mean                    \n",
    "        \n",
    "    return weighted_mean_weight_description    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# this part copied from shrinkbench\n",
    "\n",
    "def nonzero(tensor):\n",
    "    \"\"\"Returns absolute number of values different from 0\n",
    "\n",
    "    Arguments:\n",
    "        tensor {numpy.ndarray} -- Array to compute over\n",
    "\n",
    "    Returns:\n",
    "        int -- Number of nonzero elements\n",
    "    \"\"\"\n",
    "    return np.sum(tensor != 0.0)\n",
    "\n",
    "\n",
    "def model_size(model, as_bits=False):\n",
    "    \"\"\"Returns absolute and nonzero model size\n",
    "\n",
    "    Arguments:\n",
    "        model {torch.nn.Module} -- Network to compute model size over\n",
    "\n",
    "    Keyword Arguments:\n",
    "        as_bits {bool} -- Whether to account for the size of dtype\n",
    "\n",
    "    Returns:\n",
    "        int -- Total number of weight & bias params\n",
    "        int -- Out total_params exactly how many are nonzero\n",
    "    \"\"\"\n",
    "\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    for tensor in model.parameters():\n",
    "        t = np.prod(tensor.shape)\n",
    "        nz = nonzero(tensor.detach().cpu().numpy())\n",
    "        if as_bits:\n",
    "            bits = dtype2bits[tensor.dtype]\n",
    "            t *= bits\n",
    "            nz *= bits\n",
    "        total_params += t\n",
    "        nonzero_params += nz\n",
    "    return int(total_params), int(nonzero_params)\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))        \n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes how many correct outputs with respect to targets\n",
    "\n",
    "    Does NOT compute accuracy but just a raw amount of correct\n",
    "    outputs given target labels. This is done for each value in\n",
    "    topk. A value is considered correct if target is in the topk\n",
    "    highest values of output.\n",
    "    The values returned are upperbounded by the given batch size\n",
    "\n",
    "    [description]\n",
    "\n",
    "    Arguments:\n",
    "        output {torch.Tensor} -- Output prediction of the model\n",
    "        target {torch.Tensor} -- Target labels from data\n",
    "\n",
    "    Keyword Arguments:\n",
    "        topk {iterable} -- [Iterable of values of k to consider as correct] (default: {(1,)})\n",
    "\n",
    "    Returns:\n",
    "        List(int) -- Number of correct values for each topk\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        # Only need to do topk for highest k, reuse for the rest\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(torch.tensor(correct_k.item()))\n",
    "        return res\n",
    "\n",
    "\n",
    "# below copied from shrinkbench, to be used later\n",
    "# def accuracy(model, dataloader, topk=(1,)):\n",
    "#     \"\"\"Compute accuracy of a model over a dataloader for various topk\n",
    "\n",
    "#     Arguments:\n",
    "#         model {torch.nn.Module} -- Network to evaluate\n",
    "#         dataloader {torch.utils.data.DataLoader} -- Data to iterate over\n",
    "\n",
    "#     Keyword Arguments:\n",
    "#         topk {iterable} -- [Iterable of values of k to consider as correct] (default: {(1,)})\n",
    "\n",
    "#     Returns:\n",
    "#         List(float) -- List of accuracies for each topk\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Use same device as model\n",
    "#     device = next(model.parameters()).device\n",
    "\n",
    "#     accs = np.zeros(len(topk))\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for i, (input, target) in enumerate(dataloader):\n",
    "#             input = input.to(device)\n",
    "#             target = target.to(device)\n",
    "#             output = model(input)\n",
    "\n",
    "#             accs += np.array(correct(output, target, topk))\n",
    "\n",
    "#     # Normalize over data length\n",
    "#     accs /= len(dataloader.dataset)\n",
    "\n",
    "#     return accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    \n",
    "    \n",
    "def evaluate(model, val_loader):\n",
    "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "#     print(\"outputs are \",outputs)\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD,\n",
    "        weight_description=None,mask_whole_model=None,range_params=None,upscale=None,\n",
    "       mean_weight_description_weighted=None):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    print(\"At train\")\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        if mask_whole_model and range_params and upscale:\n",
    "            # regenerate mask\n",
    "            new_mask_list=prune_mean_weights_get_mask_bezier(model,range_params,upscale,mean_weight_description_weighted)\n",
    "            mask_whole_model=combineMasks(new_mask_list,mask_whole_model)\n",
    "            apply_mask_model(model,mask_whole_model)\n",
    "\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "#         print(\"wt desc = \",weight_description)\n",
    "        if weight_description!=None:\n",
    "            print(\"going for weight\")\n",
    "            weight_description=store_weights_in_dic(weight_description,model)\n",
    "    return history, weight_description,mask_whole_model\n",
    "\n",
    "\n",
    "\n",
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self):\n",
    "        super(CIFAR10CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.fc3.is_classifier = True\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        top_1, top_5 = correct(out, labels,topk=(1,5))\n",
    "#         print(\"Batch is \",batch[1].shape)\n",
    "        \n",
    "        top_1=top_1/batch[1].shape[0]\n",
    "        top_5=top_5/batch[1].shape[0]\n",
    "\n",
    "#         print(\"corr\",top_1,top_5)\n",
    "#         return {'val_loss': loss, 'val_acc': acc}\n",
    "        return {'val_loss': loss, 'val_acc': acc, 'top_1': top_1, 'top_5': top_5}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        \n",
    "        batch_top_1s = [x['top_1'] for x in outputs]\n",
    "#         print(batch_top_1s)\n",
    "        epoch_top_1 = torch.stack(batch_top_1s).mean()      # Combine top_1\n",
    "        \n",
    "        batch_top_5s = [x['top_5'] for x in outputs]\n",
    "        epoch_top_5 = torch.stack(batch_top_5s).mean()      # Combine top_5\n",
    "        \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(),\n",
    "               'val_top_1': epoch_top_1.item(), 'val_top_5': epoch_top_5.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}, val_top_1: {:.4f}, val_top_5: {:.4f}\".format(\n",
    "                                epoch, result['val_loss'], result['val_acc'], \n",
    "                                result['val_top_1'], result['val_top_5']))\n",
    "        \n",
    "        \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program To apply beizier on mean weight on CIFAR10\n",
      "Torch cuda  False\n",
      "device  cpu\n",
      "Files already downloaded and verified\n",
      "initial result [{'val_loss': 2.303389072418213, 'val_acc': 0.09804687649011612, 'val_top_1': 0.09804687649011612, 'val_top_5': 0.508007824420929}]\n",
      "after loading result [{'val_loss': 1.1301158666610718, 'val_acc': 0.597851574420929, 'val_top_1': 0.597851574420929, 'val_top_5': 0.9546874761581421}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Program To apply beizier on mean weight on CIFAR10\")\n",
    "\n",
    "print(\"Torch cuda \",torch.cuda.is_available())\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(\"device \",device)\n",
    "\n",
    "# data_transforms=torchvision.transforms.Compose(\n",
    "#     [torchvision.transforms.Resize((28,28)),torchvision.transforms.ToTensor()])\n",
    "\n",
    "\n",
    "data_transforms=torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()])\n",
    "\n",
    "\n",
    "dataset = CIFAR10(root='data/', download=True, transform=data_transforms)\n",
    "\n",
    "\n",
    "# Define test dataset\n",
    "test_dataset = CIFAR10(root='data/', train=False,transform=data_transforms)\n",
    "\n",
    "\n",
    "\n",
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "# test_loader=val_loader\n",
    "\n",
    "shape=dataset[0][0].shape\n",
    "input_size=1\n",
    "for s in shape:\n",
    "    input_size*=s\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "targets=train_ds.dataset.targets\n",
    "training_data=torch.tensor(train_ds.dataset.data)\n",
    "\n",
    "training_data = training_data.to(device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model=CIFAR10CNN()\n",
    "# model.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()\n",
    "history = [evaluate(model, val_loader)]\n",
    "print(\"initial result\",history)\n",
    "weight_description={}\n",
    "\n",
    "lr=0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_state_path=\"model_state/mod_CNN.pt\"\n",
    "if torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load(model_state_path))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(model_state_path,map_location=torch.device('cpu')))\n",
    "# model=model.to_device()\n",
    "history = [evaluate(model, val_loader)]\n",
    "print(\"after loading result\",history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_few=50\n",
    "weight_description= pickle.load( open( \"pickles/weight_description_CNN.p\", \"rb\" ) )\n",
    "mean_weight_description_weighted=get_weighted_mean_dict_weight_dict(weight_description,last_few)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['conv1.weight', 'conv2.weight', 'fc1.weight', 'fc2.weight', 'fc3.weight'])\n"
     ]
    }
   ],
   "source": [
    "print(mean_weight_description_weighted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineMasks(mask1,mask2):\n",
    "    mask_new=[]\n",
    "    for i in range(len(mask1)):\n",
    "        m_1=mask1[i]\n",
    "        m_2=mask2[i]\n",
    "#         print(m_1[0])\n",
    "#         print(m_2[0])        \n",
    "        m_new=np.multiply(m_1,m_2)\n",
    "#         print(m_new[0])        \n",
    "        mask_new.append(m_new)\n",
    "    return mask_new\n",
    "    \n",
    "def prune_mean_weights_get_mask_bezier(model,range_params,upscale,mean_weight_description_weighted):\n",
    "    ax,bx,cx,dx=range_params\n",
    "    mask_whole_model=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)\n",
    "#             print(nm,params.shape)\n",
    "            num_components=len(mean_weight_description_weighted[nm].keys())\n",
    "#             print(\"Number of components are \",num_components)\n",
    "            number_of_bins=int(math.sqrt(len(mean_weight_description_weighted[nm][0].keys())))\n",
    "            if number_of_bins%2==1:\n",
    "                number_of_bins+=1\n",
    "#             print(\"Number of bins = \",number_of_bins)\n",
    "            # creating the bezier curve\n",
    "            x=np.linspace(1,0,number_of_bins//2)\n",
    "            y1=ax*(1-x)**3 + bx*3*x*(1-x)**2 + cx*3*(x**2)*(1-x) + dx*(x**3)\n",
    "            x=np.linspace(0,1,number_of_bins//2)\n",
    "            y2=ax*(1-x)**3 + bx*3*x*(1-x)**2 + cx*3*(x**2)*(1-x) + dx*(x**3)\n",
    "\n",
    "            proportion=torch.tensor(np.concatenate((y1,y2)))\n",
    "            # normalizing to be between 0 and 1\n",
    "            proportion=(proportion-torch.min(proportion))/(torch.max(proportion)-torch.min(proportion))\n",
    "            # now let us scale up the values\n",
    "            proportion=proportion*upscale\n",
    "#             print(\"Proportion is \",proportion)\n",
    "\n",
    "\n",
    "\n",
    "            for index_component in range(num_components):\n",
    "#                 print(\"Component number \",index_component)\n",
    "                model_values=params[index_component]\n",
    "                values=torch.tensor(list(mean_weight_description_weighted[nm][index_component].values()))\n",
    "    #             print(values.shape)\n",
    "    #             print(\"number of non 0s\",torch.count_nonzero(values))\n",
    "                if len(values.shape)==3:\n",
    "                    re_shaped_values=values.flatten()\n",
    "                else:\n",
    "                    re_shaped_values=values\n",
    "                mask_vals=torch.ones(re_shaped_values.shape)\n",
    "    #             print(\"Shape of mask is \",mask_vals.shape)\n",
    "                sorted_indices=torch.argsort(re_shaped_values)\n",
    "    #             print(\"Sorted indices are \",sorted_indices)\n",
    "                #sorts from lowest to highest\n",
    "                min_weight=torch.min(re_shaped_values).item()\n",
    "                max_weight=torch.max(re_shaped_values).item()            \n",
    "                bin_vals=torch.histc(re_shaped_values, bins=number_of_bins, min=min_weight, max=min_weight)\n",
    "    #             print(\"bins created for hist=\",bin_vals.shape,\"vals are \",bin_vals)\n",
    "                start_index=0\n",
    "                for bin_index  in range(bin_vals.shape[0]):\n",
    "    #                 print(\"Bin number \",bin_index)\n",
    "                    # find how many elements are there in each bin\n",
    "                    each_bin_count=int(bin_vals[bin_index].item())\n",
    "    #                 print(\"from\",start_index,\"to\",start_index+each_bin_count)\n",
    "                    elem_indices=sorted_indices[start_index:start_index+each_bin_count]\n",
    "                    # find the proportion of elements to be pruned from this bin\n",
    "                    proportion_to_prune=min(proportion[bin_index],1)\n",
    "                    count_to_prune=int(len(elem_indices)*proportion_to_prune)\n",
    "    #                 print(\"proportion and count to prune\",proportion_to_prune,count_to_prune)\n",
    "                    selected_indices_prune=random.sample(list(elem_indices),count_to_prune)\n",
    "    #                 print(selected_indices_prune,\"out of \",elem_indices,\"to be pruned\")\n",
    "                    for to_p_index in selected_indices_prune:\n",
    "                        mask_vals[to_p_index]=0                \n",
    "                    start_index+=each_bin_count\n",
    "                    # done with each bins\n",
    "\n",
    "                # done with each neurons/filters\n",
    "                mask_vals=mask_vals.reshape(model_values.shape)\n",
    "                mask_layer[index_component]=mask_vals\n",
    "    #             print(\"At the end of each component, \",values.shape,mask_vals.shape)\n",
    "            # done with weight in paramter name\n",
    "            mask_whole_model.append(mask_layer)\n",
    "\n",
    "        # done with a layer\n",
    "    \n",
    "    return mask_whole_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upscale by  0.07\n",
      "0 / 100\n",
      "At train\n",
      "Epoch [0], val_loss: 1.1244, val_acc: 0.5998, val_top_1: 0.5998, val_top_5: 0.9578\n",
      "Compression= 0.028529497145437538 Result after re training is  {'val_loss': 1.1917107105255127, 'val_acc': 0.5777343511581421, 'val_top_1': 0.5777343511581421, 'val_top_5': 0.950878918170929} Going for re training\n",
      "********************\n",
      "1 / 100\n",
      "At train\n",
      "Epoch [0], val_loss: 1.1427, val_acc: 0.5908, val_top_1: 0.5908, val_top_5: 0.9512\n",
      "Compression= 0.04160887656033287 Result after re training is  {'val_loss': 1.206607460975647, 'val_acc': 0.5663086175918579, 'val_top_1': 0.5663086175918579, 'val_top_5': 0.9486328363418579} Going for re training\n",
      "********************\n",
      "2 / 100\n",
      "At train\n",
      "Epoch [0], val_loss: 1.4285, val_acc: 0.5201, val_top_1: 0.5201, val_top_5: 0.9130\n",
      "Compression= 0.05423668677224785 Result after re training is  {'val_loss': 1.4856196641921997, 'val_acc': 0.5054687261581421, 'val_top_1': 0.5054687261581421, 'val_top_5': 0.911914050579071} Going for re training\n",
      "********************\n",
      "3 / 100\n",
      "At train\n",
      "Epoch [0], val_loss: 1.1394, val_acc: 0.6007, val_top_1: 0.6007, val_top_5: 0.9537\n",
      "Compression= 0.06597748604973712 Result after re training is  {'val_loss': 1.2011820077896118, 'val_acc': 0.58056640625, 'val_top_1': 0.58056640625, 'val_top_5': 0.9491211175918579} Going for re training\n",
      "********************\n",
      "4 / 100\n",
      "At train\n",
      "Epoch [0], val_loss: 1.2139, val_acc: 0.5800, val_top_1: 0.5800, val_top_5: 0.9437\n",
      "Compression= 0.07749250072573621 Result after re training is  {'val_loss': 1.2674288749694824, 'val_acc': 0.556640625, 'val_top_1': 0.556640625, 'val_top_5': 0.94189453125} Going for re training\n",
      "********************\n",
      "5 / 100\n",
      "At train\n",
      "Epoch [0], val_loss: 1.1800, val_acc: 0.5857, val_top_1: 0.5857, val_top_5: 0.9479\n",
      "Compression= 0.08860432861336 Result after re training is  {'val_loss': 1.226987600326538, 'val_acc': 0.5665038824081421, 'val_top_1': 0.5665038824081421, 'val_top_5': 0.945019543170929} Going for re training\n",
      "********************\n",
      "6 / 100\n",
      "At train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3356386/1209980414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#             print(\"Compression=\",compression,\"Result after pruning is \",res,\"Going for re training\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             history_prune,_,list_mask_whole_model = fit(epochs, lr, model, train_loader, val_loader,\n\u001b[0m\u001b[1;32m     36\u001b[0m                               \u001b[0mmask_whole_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist_mask_whole_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                              \u001b[0mrange_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3356386/469578227.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, lr, model, train_loader, val_loader, opt_func, weight_description, mask_whole_model, range_params, upscale, mean_weight_description_weighted)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# Training Phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3356386/469578227.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3356386/469578227.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# flatten all dimensions except batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.8/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    154\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                             self.return_indices)\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.8/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     return torch.max_pool2d(\n\u001b[0m\u001b[1;32m    586\u001b[0m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dict_results={}\n",
    "dict_results[\"range_params\"]=[]\n",
    "dict_results[\"upscale\"]=[]\n",
    "dict_results[\"epoch_number\"]=[]\n",
    "dict_results[\"compression\"]=[]\n",
    "dict_results[\"val_top_1\"]=[]\n",
    "\n",
    "\n",
    "range_params_list=[\n",
    "    [1,0.8,0.8,.8],\n",
    "]\n",
    "for range_params in range_params_list:\n",
    "    upscale_list=[0.07, 0.09, 0.1, 0.3, 0.5, 1,5,9,12,14]\n",
    "    for upscale in upscale_list:\n",
    "        print(\"Upscale by \",upscale)\n",
    "        model_state_path=\"model_state/mod_CNN.pt\"\n",
    "        if torch.cuda.is_available():\n",
    "            model.load_state_dict(torch.load(model_state_path))\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(model_state_path,map_location=torch.device('cpu')))\n",
    "\n",
    "        list_mask_whole_model=prune_mean_weights_get_mask_bezier(model,\n",
    "                                                                 range_params,\n",
    "                                                                 upscale,mean_weight_description_weighted)\n",
    "        i=0\n",
    "        turns=100\n",
    "        while i<turns:\n",
    "            print(i,\"/\",turns)\n",
    "            apply_mask_model(model,list_mask_whole_model)\n",
    "            total_size,nz_size=model_size(model)\n",
    "            compression=(total_size-nz_size)/total_size\n",
    "            res = evaluate(model, test_loader)\n",
    "#             print(\"Compression=\",compression,\"Result after pruning is \",res,\"Going for re training\")\n",
    "            epochs=1\n",
    "            history_prune,_,list_mask_whole_model = fit(epochs, lr, model, train_loader, val_loader,\n",
    "                              mask_whole_model=list_mask_whole_model,\n",
    "                             range_params=range_params,\n",
    "                             upscale=upscale,mean_weight_descwription_weighted=mean_weight_description_weighted)\n",
    "\n",
    "            total_size,nz_size=model_size(model)\n",
    "            compression=(total_size-nz_size)/total_size\n",
    "            res = evaluate(model, test_loader)\n",
    "            print(\"Compression=\",compression,\"Result after re training is \",res,\"Going for re training\")\n",
    "            \n",
    "            dict_results[\"range_params\"].append(range_params)\n",
    "            dict_results[\"upscale\"].append(upscale)\n",
    "            dict_results[\"epoch_number\"].append(i)\n",
    "            dict_results[\"compression\"].append(compression)\n",
    "            dict_results[\"val_top_1\"].append(res[\"val_top_1\"])\n",
    "\n",
    "            \n",
    "            i+=1\n",
    "            print(\"*\"*20)\n",
    "        print(\"=\"*20)\n",
    "        \n",
    "df=pd.DataFrame(dict_results)            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "df.to_csv(os.path.join(\"results_sheet\",\"bezier_metrics_meanWts100X9.csv\"),index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_bezier=df\n",
    "upscales=df_bezier.upscale.unique()\n",
    "for upscale in upscales:\n",
    "    df_bezier_upscale=df_bezier[df_bezier[\"upscale\"]==upscale]\n",
    "    \n",
    "    df_bezier_upscale=df_bezier_upscale.sort_values(by=[\"compression\"],ascending=True)\n",
    "    ys=df_bezier_upscale[\"val_top_1\"].values\n",
    "    xs=df_bezier_upscale[\"compression\"].values\n",
    "    # xxs=(xs[argrelextrema(ys, np.greater)[0]])\n",
    "    # yys=(ys[argrelextrema(ys, np.greater)[0]])\n",
    "    fig.add_trace(go.Scatter(x=xs, y=ys,\n",
    "                    mode='lines+markers',\n",
    "                    name=\"Bezier_\"+str(upscale)))\n",
    "\n",
    "fig.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_kernel",
   "language": "python",
   "name": "prune_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
