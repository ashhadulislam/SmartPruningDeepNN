{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program FashionMNIST 04_Bezier_Actual_Weights.py\n",
      "Torch cuda  False\n",
      "device  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3465572/3873542197.py:473: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  training_data=torch.tensor(train_ds.dataset.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial result [{'val_loss': 2.3038628101348877, 'val_acc': 0.09941406548023224, 'val_top_1': 0.09941406548023224, 'val_top_5': 0.502148449420929}]\n",
      "Test result is  {'val_loss': 0.35806748270988464, 'val_acc': 0.871874988079071, 'val_top_1': 0.871874988079071, 'val_top_5': 0.9970703125}\n",
      "Compression= 0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import pickle\n",
    "import os\n",
    "from scipy import stats\n",
    "    \n",
    "\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def countDiffMasks(mask1,mask2):\n",
    "    total_diff=0\n",
    "    for i in range(len(mask1)):\n",
    "        m_1=mask1[i].flatten()\n",
    "        m_2=mask2[i].flatten()\n",
    "        count_same=(m_1 == m_2).sum()\n",
    "        count_different=m_1.flatten().shape[0]-count_same\n",
    "        total_diff+=count_different\n",
    "    return total_diff\n",
    "\n",
    "def combineMasks(mask1,mask2):\n",
    "    mask_new=[]\n",
    "    for i in range(len(mask1)):\n",
    "        m_1=mask1[i]\n",
    "        m_2=mask2[i]\n",
    "#         print(m_1[0])\n",
    "#         print(m_2[0])        \n",
    "        m_new=np.multiply(m_1,m_2)\n",
    "#         print(m_new[0])        \n",
    "        mask_new.append(m_new)\n",
    "    return mask_new\n",
    "\n",
    "\n",
    "\n",
    "def get_mask_compression(mask_whole_model):\n",
    "    num_total=0\n",
    "    num_non_zeros=0\n",
    "    for mask_each_layer in mask_whole_model:\n",
    "        num_total+=torch.numel(mask_each_layer)\n",
    "        num_non_zeros+=torch.count_nonzero(mask_each_layer)\n",
    "        \n",
    "    return (num_total-num_non_zeros)/num_total\n",
    "\n",
    "    \n",
    "    \n",
    "def prune_model_get_mask_bezier(model,range_params,upscale,upscale_method):\n",
    "    ax,bx,cx,dx=range_params\n",
    "    mask_whole_model=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)\n",
    "#             print(nm,params.shape)\n",
    "            num_components=params.shape[0]\n",
    "#             print(\"Number of components are \",num_components)\n",
    "            number_of_bins=int(math.sqrt(torch.numel(params[0])))\n",
    "            if number_of_bins%2==1:\n",
    "                number_of_bins+=1\n",
    "#             print(\"Number of bins = \",number_of_bins)\n",
    "            # creating the bezier curve\n",
    "            x=np.linspace(1,0,number_of_bins//2)\n",
    "            y1=ax*(1-x)**3 + bx*3*x*(1-x)**2 + cx*3*(x**2)*(1-x) + dx*(x**3)\n",
    "            x=np.linspace(0,1,number_of_bins//2)\n",
    "            y2=ax*(1-x)**3 + bx*3*x*(1-x)**2 + cx*3*(x**2)*(1-x) + dx*(x**3)\n",
    "\n",
    "            proportion=torch.tensor(np.concatenate((y1,y2)))\n",
    "            # normalizing to be between 0 and 1\n",
    "            proportion=(proportion-torch.min(proportion))/(torch.max(proportion)-torch.min(proportion))\n",
    "            # now let us scale up the values\n",
    "            if upscale_method==\"+\":\n",
    "                proportion=proportion+upscale\n",
    "            elif upscale_method==\"*\":\n",
    "                proportion=proportion*upscale            \n",
    "#             print(\"Proportion is \",proportion)\n",
    "\n",
    "\n",
    "\n",
    "            for index_component in range(num_components):\n",
    "#                 print(\"Component number \",index_component)\n",
    "                values=params[index_component]\n",
    "    #             print(values.shape)\n",
    "    #             print(\"number of non 0s\",torch.count_nonzero(values))\n",
    "                if len(values.shape)==3:\n",
    "                    re_shaped_values=values.flatten()\n",
    "                else:\n",
    "                    re_shaped_values=values\n",
    "                mask_vals=torch.ones(re_shaped_values.shape)\n",
    "    #             print(\"Shape of mask is \",mask_vals.shape)\n",
    "                sorted_indices=torch.argsort(re_shaped_values)\n",
    "    #             print(\"Sorted indices are \",sorted_indices)\n",
    "                #sorts from lowest to highest\n",
    "                min_weight=torch.min(re_shaped_values).item()\n",
    "                max_weight=torch.max(re_shaped_values).item()            \n",
    "                bin_vals=torch.histc(re_shaped_values, bins=number_of_bins, min=min_weight, max=min_weight)\n",
    "    #             print(\"bins created for hist=\",bin_vals.shape,\"vals are \",bin_vals)\n",
    "                start_index=0\n",
    "                for bin_index  in range(bin_vals.shape[0]):\n",
    "    #                 print(\"Bin number \",bin_index)\n",
    "                    # find how many elements are there in each bin\n",
    "                    each_bin_count=int(bin_vals[bin_index].item())\n",
    "    #                 print(\"from\",start_index,\"to\",start_index+each_bin_count)\n",
    "                    elem_indices=sorted_indices[start_index:start_index+each_bin_count]\n",
    "                    # find the proportion of elements to be pruned from this bin\n",
    "                    proportion_to_prune=min(proportion[bin_index],1)\n",
    "                    count_to_prune=int(len(elem_indices)*proportion_to_prune)\n",
    "    #                 print(\"proportion and count to prune\",proportion_to_prune,count_to_prune)\n",
    "                    selected_indices_prune=random.sample(list(elem_indices),count_to_prune)\n",
    "    #                 print(selected_indices_prune,\"out of \",elem_indices,\"to be pruned\")\n",
    "                    for to_p_index in selected_indices_prune:\n",
    "                        mask_vals[to_p_index]=0                \n",
    "                    start_index+=each_bin_count\n",
    "                    # done with each bins\n",
    "\n",
    "                # done with each neurons/filters\n",
    "                mask_vals=mask_vals.reshape(values.shape)\n",
    "                mask_layer[index_component]=mask_vals\n",
    "    #             print(\"At the end of each component, \",values.shape,mask_vals.shape)\n",
    "            # done with weight in paramter name\n",
    "            mask_whole_model.append(mask_layer)\n",
    "\n",
    "        # done with a layer\n",
    "    \n",
    "    return mask_whole_model\n",
    " \n",
    "    \n",
    "def get_thresholds_each_layer(model,prune_rate):\n",
    "    thresholds_per_layer=[]\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=torch.ones(params.shape)\n",
    "            abs_std=torch.std(torch.abs(params.data))\n",
    "            threshold=abs_std*prune_rate\n",
    "            thresholds_per_layer.append(threshold)\n",
    "    return thresholds_per_layer\n",
    "    \n",
    "                \n",
    "def apply_mask_model(model,list_mask_whole_model):\n",
    "    mask_layer_count=0\n",
    "    for nm, params in model.named_parameters():\n",
    "        if \"weight\" in nm and \"bn\" not in nm and \"linear\" not in nm:\n",
    "            mask_layer=list_mask_whole_model[mask_layer_count]\n",
    "            with torch.no_grad():\n",
    "                device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#                 print(\"Devices are \",params.device,mask_layer.device)\n",
    "                mask_layer=mask_layer.to(device)\n",
    "    \n",
    "                params.data=params.data*mask_layer            \n",
    "            mask_layer_count+=1\n",
    "    \n",
    "\n",
    "\n",
    "                \n",
    "import math\n",
    "\n",
    "\n",
    "# this part copied from shrinkbench\n",
    "\n",
    "def nonzero(tensor):\n",
    "    \"\"\"Returns absolute number of values different from 0\n",
    "\n",
    "    Arguments:\n",
    "        tensor {numpy.ndarray} -- Array to compute over\n",
    "\n",
    "    Returns:\n",
    "        int -- Number of nonzero elements\n",
    "    \"\"\"\n",
    "    return np.sum(tensor != 0.0)\n",
    "\n",
    "\n",
    "def model_size(model, as_bits=False):\n",
    "    \"\"\"Returns absolute and nonzero model size\n",
    "\n",
    "    Arguments:\n",
    "        model {torch.nn.Module} -- Network to compute model size over\n",
    "\n",
    "    Keyword Arguments:\n",
    "        as_bits {bool} -- Whether to account for the size of dtype\n",
    "\n",
    "    Returns:\n",
    "        int -- Total number of weight & bias params\n",
    "        int -- Out total_params exactly how many are nonzero\n",
    "    \"\"\"\n",
    "\n",
    "    total_params = 0\n",
    "    nonzero_params = 0\n",
    "    for tensor in model.parameters():\n",
    "        t = np.prod(tensor.shape)\n",
    "        nz = nonzero(tensor.detach().cpu().numpy())\n",
    "        if as_bits:\n",
    "            bits = dtype2bits[tensor.dtype]\n",
    "            t *= bits\n",
    "            nz *= bits\n",
    "        total_params += t\n",
    "        nonzero_params += nz\n",
    "    return int(total_params), int(nonzero_params)\n",
    "\n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))        \n",
    "\n",
    "def correct(output, target, topk=(1,)):\n",
    "    \"\"\"Computes how many correct outputs with respect to targets\n",
    "\n",
    "    Does NOT compute accuracy but just a raw amount of correct\n",
    "    outputs given target labels. This is done for each value in\n",
    "    topk. A value is considered correct if target is in the topk\n",
    "    highest values of output.\n",
    "    The values returned are upperbounded by the given batch size\n",
    "\n",
    "    [description]\n",
    "\n",
    "    Arguments:\n",
    "        output {torch.Tensor} -- Output prediction of the model\n",
    "        target {torch.Tensor} -- Target labels from data\n",
    "\n",
    "    Keyword Arguments:\n",
    "        topk {iterable} -- [Iterable of values of k to consider as correct] (default: {(1,)})\n",
    "\n",
    "    Returns:\n",
    "        List(int) -- Number of correct values for each topk\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        # Only need to do topk for highest k, reuse for the rest\n",
    "        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(torch.tensor(correct_k.item()))\n",
    "        return res\n",
    "\n",
    "\n",
    "# below copied from shrinkbench, to be used later\n",
    "# def accuracy(model, dataloader, topk=(1,)):\n",
    "#     \"\"\"Compute accuracy of a model over a dataloader for various topk\n",
    "\n",
    "#     Arguments:\n",
    "#         model {torch.nn.Module} -- Network to evaluate\n",
    "#         dataloader {torch.utils.data.DataLoader} -- Data to iterate over\n",
    "\n",
    "#     Keyword Arguments:\n",
    "#         topk {iterable} -- [Iterable of values of k to consider as correct] (default: {(1,)})\n",
    "\n",
    "#     Returns:\n",
    "#         List(float) -- List of accuracies for each topk\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Use same device as model\n",
    "#     device = next(model.parameters()).device\n",
    "\n",
    "#     accs = np.zeros(len(topk))\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for i, (input, target) in enumerate(dataloader):\n",
    "#             input = input.to(device)\n",
    "#             target = target.to(device)\n",
    "#             output = model(input)\n",
    "\n",
    "#             accs += np.array(correct(output, target, topk))\n",
    "\n",
    "#     # Normalize over data length\n",
    "#     accs /= len(dataloader.dataset)\n",
    "\n",
    "#     return accs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# LENET 300-100 for MNIST and comparison\n",
    "class FashionMnistNet(nn.Module):\n",
    "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FashionMnistNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)        \n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.fc4.is_classifier = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))        \n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        top_1, top_5 = correct(out, labels,topk=(1,5))\n",
    "#         print(\"Batch is \",batch[1].shape)\n",
    "        \n",
    "        top_1=top_1/batch[1].shape[0]\n",
    "        top_5=top_5/batch[1].shape[0]\n",
    "\n",
    "#         print(\"corr\",top_1,top_5)\n",
    "#         return {'val_loss': loss, 'val_acc': acc}\n",
    "        return {'val_loss': loss, 'val_acc': acc, 'top_1': top_1, 'top_5': top_5}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        \n",
    "        batch_top_1s = [x['top_1'] for x in outputs]\n",
    "#         print(batch_top_1s)\n",
    "        epoch_top_1 = torch.stack(batch_top_1s).mean()      # Combine top_1\n",
    "        \n",
    "        batch_top_5s = [x['top_5'] for x in outputs]\n",
    "        epoch_top_5 = torch.stack(batch_top_5s).mean()      # Combine top_5\n",
    "        \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item(),\n",
    "               'val_top_1': epoch_top_1.item(), 'val_top_5': epoch_top_5.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}, val_top_1: {:.4f}, val_top_5: {:.4f}\".format(\n",
    "                                epoch, result['val_loss'], result['val_acc'], \n",
    "                                result['val_top_1'], result['val_top_5']))\n",
    "        \n",
    "        \n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "    \n",
    "    \n",
    "def evaluate(model, val_loader):\n",
    "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "#     print(\"outputs are \",outputs)\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD,\n",
    "        weight_description=None,mask_whole_model=None,range_params=None,upscale=None,\n",
    "       model_state_path=None,upscale_method=None):\n",
    "    \"\"\"Train the model using gradient descent\"\"\"\n",
    "    print(\"At train\")\n",
    "    history = []\n",
    "    best_so_far=-999    \n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        if mask_whole_model and range_params and upscale:\n",
    "            # regenerate mask\n",
    "            new_mask_list=prune_model_get_mask_bezier(model,range_params,upscale,upscale_method)\n",
    "            mask_whole_model=combineMasks(new_mask_list,mask_whole_model)\n",
    "            apply_mask_model(model,mask_whole_model)\n",
    "\n",
    "        result = evaluate(model, val_loader)\n",
    "        if best_so_far<result[\"val_top_1\"]:\n",
    "            best_so_far=result[\"val_top_1\"]\n",
    "            if model_state_path:\n",
    "                torch.save(model.state_dict(), model_state_path)\n",
    "        \n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "#         print(\"wt desc = \",weight_description)\n",
    "        if weight_description!=None:\n",
    "            print(\"going for weight\")\n",
    "            weight_description=store_weights_in_dic(weight_description,model)\n",
    "    return history, weight_description,mask_whole_model\n",
    "\n",
    "\n",
    "def predict_image(img, model):\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()\n",
    "\n",
    "\n",
    "print(\"Program FashionMNIST 04_Bezier_Actual_Weights.py\")\n",
    "\n",
    "print(\"Torch cuda \",torch.cuda.is_available())\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "print(\"device \",device)\n",
    "\n",
    "\n",
    "\n",
    "dataset = FashionMNIST(root='data/', download=True, transform=ToTensor())\n",
    "\n",
    "\n",
    "# Define test dataset\n",
    "test_dataset = FashionMNIST(root='data/', train=False,transform=ToTensor())\n",
    "\n",
    "val_size = 10000\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "shape=dataset[0][0].shape\n",
    "input_size=1\n",
    "for s in shape:\n",
    "    input_size*=s\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "train_loader = DeviceDataLoader(train_loader, device)\n",
    "val_loader = DeviceDataLoader(val_loader, device)\n",
    "test_loader = DeviceDataLoader(test_loader, device)\n",
    "\n",
    "targets=train_ds.dataset.targets\n",
    "training_data=torch.tensor(train_ds.dataset.data)\n",
    "\n",
    "training_data = training_data.to(device=device)\n",
    "\n",
    "\n",
    "model=FashionMnistNet()\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()\n",
    "history = [evaluate(model, val_loader)]\n",
    "print(\"initial result\",history)\n",
    "weight_description={}\n",
    "epochs=50\n",
    "lr=0.01\n",
    "\n",
    "\n",
    "\n",
    "model_state_path=\"model_state/mod.pt\"\n",
    "model.load_state_dict(torch.load(model_state_path))\n",
    "\n",
    "\n",
    "result = evaluate(model, test_loader)\n",
    "print(\"Test result is \",result)\n",
    "\n",
    "\n",
    "total_size,nz_size=model_size(model)\n",
    "compression=(total_size-nz_size)/total_size\n",
    "print(\"Compression=\",compression)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dict_results={}\n",
    "dict_results[\"range_params\"]=[]\n",
    "dict_results[\"upscale\"]=[]\n",
    "dict_results[\"upscale_method\"]=[]\n",
    "dict_results[\"epoch_number\"]=[]\n",
    "dict_results[\"compression\"]=[]\n",
    "dict_results[\"val_top_1\"]=[]\n",
    "\n",
    "\n",
    "range_params_list=[\n",
    "    [1,0.14,0.14,0.1],\n",
    "#     [1,0.33,0.28,0.24],\n",
    "#     [0.81,0.66,0.62,0.57],\n",
    "#     [1,1,0.14,0.1],\n",
    "#     [0.71,0.71,0.38,0.14],\n",
    "#     [0.71,0.66,0.66,0.19],\n",
    "#     [0.81,0.81,0.81,0.71],\n",
    "#     [1,1,1,0.95],\n",
    "#     [1,1,1,.990909],\n",
    "#     [1,0.11,0.11,.1],\n",
    "#     [0.39, 0.13, 0.11, 0.1],\n",
    "#     [0.9, 0.55, 0.43, 0.32],\n",
    "#     [0.9, 0.9, 0.5, 0.5],    \n",
    "]\n",
    "\n",
    "# upscale_list=[0.01,\n",
    "#               0.02,\n",
    "#               0.04,\n",
    "#               0.08,\n",
    "#               0.16,\n",
    "#               0.32,\n",
    "#               0.64\n",
    "#              ]       \n",
    "upscale_list=[\n",
    "                0.20,\n",
    "#               0.24,\n",
    "#               0.28,\n",
    "#               0.36,\n",
    "#               0.40,\n",
    "#               0.48\n",
    "             ]       \n",
    "# upscale_method_list=[\"+\",\"*\"]\n",
    "upscale_method_list=[\"+\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "Model exists, loading\n",
      "[1, 0.14, 0.14, 0.1] 0.2 + 15 / 20\n",
      "At train\n",
      "Epoch [0], val_loss: 0.8814, val_acc: 0.6644, val_top_1: 0.6644, val_top_5: 0.9933\n",
      "Compression= 0.9422314859821553 Result after pruning is  {'val_loss': 0.9142875671386719, 'val_acc': 0.649218738079071, 'val_top_1': 0.649218738079071, 'val_top_5': 0.9942382574081421} Going for re training\n",
      "[1, 0.14, 0.14, 0.1] 0.2 + 16 / 20\n",
      "At train\n",
      "Epoch [0], val_loss: 0.8735, val_acc: 0.6682, val_top_1: 0.6682, val_top_5: 0.9933\n",
      "Compression= 0.9428988062382087 Result after pruning is  {'val_loss': 0.9079188108444214, 'val_acc': 0.6532226800918579, 'val_top_1': 0.6532226800918579, 'val_top_5': 0.994140625} Going for re training\n",
      "[1, 0.14, 0.14, 0.1] 0.2 + 17 / 20\n",
      "At train\n",
      "Epoch [0], val_loss: 0.8251, val_acc: 0.6832, val_top_1: 0.6832, val_top_5: 0.9938\n",
      "Compression= 0.9433848790173092 Result after pruning is  {'val_loss': 0.8577384948730469, 'val_acc': 0.6693359613418579, 'val_top_1': 0.6693359613418579, 'val_top_5': 0.994824230670929} Going for re training\n",
      "[1, 0.14, 0.14, 0.1] 0.2 + 18 / 20\n",
      "At train\n",
      "Epoch [0], val_loss: 0.7393, val_acc: 0.7116, val_top_1: 0.7116, val_top_5: 0.9942\n",
      "Compression= 0.943837997709691 Result after pruning is  {'val_loss': 0.7714155912399292, 'val_acc': 0.697949230670929, 'val_top_1': 0.697949230670929, 'val_top_5': 0.9951171875} Going for re training\n",
      "[1, 0.14, 0.14, 0.1] 0.2 + 19 / 20\n",
      "At train\n",
      "Epoch [0], val_loss: 0.7341, val_acc: 0.7157, val_top_1: 0.7157, val_top_5: 0.9943\n",
      "Compression= 0.9443529053146703 Result after pruning is  {'val_loss': 0.7671736478805542, 'val_acc': 0.698925793170929, 'val_top_1': 0.698925793170929, 'val_top_5': 0.9947265386581421} Going for re training\n",
      "           range_params  upscale upscale_method  epoch_number  compression  \\\n",
      "0  [1, 0.14, 0.14, 0.1]      0.2              +            15     0.942231   \n",
      "1  [1, 0.14, 0.14, 0.1]      0.2              +            16     0.942899   \n",
      "2  [1, 0.14, 0.14, 0.1]      0.2              +            17     0.943385   \n",
      "3  [1, 0.14, 0.14, 0.1]      0.2              +            18     0.943838   \n",
      "4  [1, 0.14, 0.14, 0.1]      0.2              +            19     0.944353   \n",
      "\n",
      "   val_top_1  \n",
      "0   0.649219  \n",
      "1   0.653223  \n",
      "2   0.669336  \n",
      "3   0.697949  \n",
      "4   0.698926  \n"
     ]
    }
   ],
   "source": [
    "for upscale_method in upscale_method_list:\n",
    "    for range_params in range_params_list:\n",
    "        for upscale in upscale_list:\n",
    "            model_state_path=\"model_state/mod.pt\"\n",
    "            model.load_state_dict(torch.load(model_state_path))\n",
    "            list_mask_whole_model=prune_model_get_mask_bezier(model,range_params,upscale,upscale_method)  \n",
    "            list_diff_masks=[]\n",
    "            i=0\n",
    "            turns=20 #200\n",
    "            while i<turns:\n",
    "                this_turn_model_state_path=\"model_state/04_bez_on_actuals/\"+str(range_params)+\"/\"+str(upscale) + \"/\" + str(upscale_method) + \"/\" + str(i) + \".pt\"\n",
    "                this_turn_list_mask_whole_model_path=\"pickles/masks/04_bez_on_actuals/\"+str(range_params)+\"/\"+str(upscale) + \"/\" + str(upscale_method) + \"/\" + str(i) + \".pkl\"\n",
    "                if os.path.isfile(this_turn_model_state_path):\n",
    "                    print(\"Model exists, loading\")\n",
    "                    if torch.cuda.is_available():\n",
    "                        model.load_state_dict(torch.load(this_turn_model_state_path))\n",
    "                    else:\n",
    "                        model.load_state_dict(torch.load(this_turn_model_state_path,map_location=torch.device('cpu')))\n",
    "                    list_mask_whole_model=pickle.load( open( this_turn_list_mask_whole_model_path, \"rb\" ) )\n",
    "                    apply_mask_model(model,list_mask_whole_model)\n",
    "#                     total_size,nz_size=model_size(model)\n",
    "#                     compression=(total_size-nz_size)/total_size\n",
    "#                     res = evaluate(model, test_loader)\n",
    "#                     print(i,\"Compression=\",compression,\"Result after pruning is \",res)\n",
    "                else:                                                        \n",
    "                    print(range_params,upscale,upscale_method,i,\"/\",turns)\n",
    "                    # apply the mask on the model\n",
    "                    epochs=1\n",
    "                    history_prune,_,list_mask_whole_model = fit(epochs, lr, model, train_loader, val_loader,\n",
    "                                      mask_whole_model=list_mask_whole_model,\n",
    "                                             range_params=range_params,\n",
    "                                             upscale=upscale,\n",
    "                                            upscale_method=upscale_method)\n",
    "                    torch.save(model.state_dict(), this_turn_model_state_path)\n",
    "                    pickle.dump( list_mask_whole_model, open( this_turn_list_mask_whole_model_path, \"wb\" ) )\n",
    "                    \n",
    "                    total_size,nz_size=model_size(model)\n",
    "                    compression=(total_size-nz_size)/total_size\n",
    "                    res = evaluate(model, test_loader)\n",
    "                    print(\"Compression=\",compression,\"Result after pruning is \",res,\"Going for re training\")\n",
    "                    dict_results[\"range_params\"].append(range_params)\n",
    "                    dict_results[\"upscale\"].append(upscale)\n",
    "                    dict_results[\"upscale_method\"].append(upscale_method)            \n",
    "                    dict_results[\"epoch_number\"].append(i)\n",
    "                    dict_results[\"compression\"].append(compression)\n",
    "                    dict_results[\"val_top_1\"].append(res[\"val_top_1\"])\n",
    "                i+=1\n",
    "        \n",
    "\n",
    "df=pd.DataFrame(dict_results)            \n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(os.path.join(\"results_sheet\",\"04bezier_on_actl_Wts17Jan2021.csv\")):\n",
    "    df_base=pd.read_csv(os.path.join(\"results_sheet\",\"04bezier_on_actl_Wts17Jan2021.csv\"))\n",
    "    df_concat=pd.concat([df_base,df])\n",
    "    df=df_concat\n",
    "\n",
    "df.to_csv(os.path.join(\"results_sheet\",\"04bezier_on_actl_Wts17Jan2021.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>range_params</th>\n",
       "      <th>upscale</th>\n",
       "      <th>upscale_method</th>\n",
       "      <th>epoch_number</th>\n",
       "      <th>compression</th>\n",
       "      <th>val_top_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>0</td>\n",
       "      <td>0.752502</td>\n",
       "      <td>0.233984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826637</td>\n",
       "      <td>0.371973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>2</td>\n",
       "      <td>0.869020</td>\n",
       "      <td>0.404980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>3</td>\n",
       "      <td>0.894786</td>\n",
       "      <td>0.416309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>4</td>\n",
       "      <td>0.910954</td>\n",
       "      <td>0.421582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>5</td>\n",
       "      <td>0.921211</td>\n",
       "      <td>0.451270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>6</td>\n",
       "      <td>0.927954</td>\n",
       "      <td>0.477246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>7</td>\n",
       "      <td>0.932135</td>\n",
       "      <td>0.532812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>8</td>\n",
       "      <td>0.934928</td>\n",
       "      <td>0.556543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>9</td>\n",
       "      <td>0.936852</td>\n",
       "      <td>0.594434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>10</td>\n",
       "      <td>0.938351</td>\n",
       "      <td>0.591602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>11</td>\n",
       "      <td>0.939294</td>\n",
       "      <td>0.623535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>12</td>\n",
       "      <td>0.940221</td>\n",
       "      <td>0.633203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>13</td>\n",
       "      <td>0.940880</td>\n",
       "      <td>0.644824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>14</td>\n",
       "      <td>0.941568</td>\n",
       "      <td>0.646191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>15</td>\n",
       "      <td>0.942231</td>\n",
       "      <td>0.649219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>16</td>\n",
       "      <td>0.942899</td>\n",
       "      <td>0.653223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>17</td>\n",
       "      <td>0.943385</td>\n",
       "      <td>0.669336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>18</td>\n",
       "      <td>0.943838</td>\n",
       "      <td>0.697949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 0.14, 0.14, 0.1]</td>\n",
       "      <td>0.2</td>\n",
       "      <td>+</td>\n",
       "      <td>19</td>\n",
       "      <td>0.944353</td>\n",
       "      <td>0.698926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            range_params  upscale upscale_method  epoch_number  compression  \\\n",
       "0   [1, 0.14, 0.14, 0.1]      0.2              +             0     0.752502   \n",
       "1   [1, 0.14, 0.14, 0.1]      0.2              +             1     0.826637   \n",
       "2   [1, 0.14, 0.14, 0.1]      0.2              +             2     0.869020   \n",
       "3   [1, 0.14, 0.14, 0.1]      0.2              +             3     0.894786   \n",
       "4   [1, 0.14, 0.14, 0.1]      0.2              +             4     0.910954   \n",
       "5   [1, 0.14, 0.14, 0.1]      0.2              +             5     0.921211   \n",
       "6   [1, 0.14, 0.14, 0.1]      0.2              +             6     0.927954   \n",
       "7   [1, 0.14, 0.14, 0.1]      0.2              +             7     0.932135   \n",
       "8   [1, 0.14, 0.14, 0.1]      0.2              +             8     0.934928   \n",
       "9   [1, 0.14, 0.14, 0.1]      0.2              +             9     0.936852   \n",
       "10  [1, 0.14, 0.14, 0.1]      0.2              +            10     0.938351   \n",
       "11  [1, 0.14, 0.14, 0.1]      0.2              +            11     0.939294   \n",
       "12  [1, 0.14, 0.14, 0.1]      0.2              +            12     0.940221   \n",
       "13  [1, 0.14, 0.14, 0.1]      0.2              +            13     0.940880   \n",
       "14  [1, 0.14, 0.14, 0.1]      0.2              +            14     0.941568   \n",
       "0   [1, 0.14, 0.14, 0.1]      0.2              +            15     0.942231   \n",
       "1   [1, 0.14, 0.14, 0.1]      0.2              +            16     0.942899   \n",
       "2   [1, 0.14, 0.14, 0.1]      0.2              +            17     0.943385   \n",
       "3   [1, 0.14, 0.14, 0.1]      0.2              +            18     0.943838   \n",
       "4   [1, 0.14, 0.14, 0.1]      0.2              +            19     0.944353   \n",
       "\n",
       "    val_top_1  \n",
       "0    0.233984  \n",
       "1    0.371973  \n",
       "2    0.404980  \n",
       "3    0.416309  \n",
       "4    0.421582  \n",
       "5    0.451270  \n",
       "6    0.477246  \n",
       "7    0.532812  \n",
       "8    0.556543  \n",
       "9    0.594434  \n",
       "10   0.591602  \n",
       "11   0.623535  \n",
       "12   0.633203  \n",
       "13   0.644824  \n",
       "14   0.646191  \n",
       "0    0.649219  \n",
       "1    0.653223  \n",
       "2    0.669336  \n",
       "3    0.697949  \n",
       "4    0.698926  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prune_kernel",
   "language": "python",
   "name": "prune_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
